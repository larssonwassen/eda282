\section{Lab 1}
\label{sec:lab1}
In this laboratory assignment, we evaluate overheads in cache coherence protocols using microbenchmarks. Three diverse benchmarks, described in section \ref{sec:lab11}, are used to compare the coherence protocols. In section \ref{sec:lab12}, MSI and MESI is compared and in section \ref{sec:lab13}, MESI and MESI-MG is compared. In each comparison, we use three working set: the first is smaller than an private L1 cache (512 counters), the second is larger than an private L1 cache and smaller than the LLC (1536 counters), and the last is larger than the LLC (98304 counters). The counters are stored in an array, the counter array, which is accessed by the benchmark.

\subsection{Task 1}
\label{sec:lab11}
Three different microbenchmarks with disgustingly various communication patterns are used in the simulations and here follow a description of each benchmark.
\subsubsection*{Benchmark 1 - Producer consumer}
In this benchmark, one thread increments the values in the counter array, whereas the other threads read these values and accumulate the read values in a private variable. However, it is not ensured that the incrementing thread increments the values before the other threads reads, and thus can this happen in any order. The counter accesses is done in mutual exclusion using a lock, and before a new lap of increments \& reads there is a barrier.

\subsubsection*{Benchmark 2 - No sharing}
This benchmark have no sharing of the counter array. The counter array is divided up equally among the threads, giving each thread access to every nth counter element, where n is the number of threads. Each thread then increments it's assigned counters sequentially. A barrier is placed before a new incrementation lap of the assigned array elements begins. 

\subsubsection*{Benchmark 3 - All shared}
In this benchmark, the counter array is shared among all threads. Each thread increments every element in the counter array sequentially while in mutual exclusion. A lock is used to provide mutual exclusion and a barrier is placed after all threads have incremented. 

\subsection{Task 2}
\label{sec:lab12}
Here the CCPs MSI and MESI are compared using benchmarks 1 and 2. The difference between the CCPs is that MESI includes an exclusive (E) state, which is beneficial if data is read exclusively by one processor. If the data is then read by another processor, a move to the shared (S) state is made without cost. I.e. MESI can only produce equal or better results than MSI.

In the producer consumer benchmark, the reading threads transition the data element to the E state when accessing the array for the first time if the writing thread have not accessed it already. However, the whole counter array is shared and thus will not state E be of any gain. Therefore, MSI and MESI performs equally regardless of working set size, which is shown in \reffig{fig:resultslab1}.

In the no sharing benchmark the first read access to every element end in state S for MSI and state E for MESI, respectively. The following write transitions the element to state M for both the CCPs, but MSI have to issue a BusUpdate whereas MESI's transition is costless. The BusUpdate broadcasts an invalidate signal which gives MSI a slight reduction in performance compared to MESI. In the small working set the elements will stay in state M to the end of execution, but in the larger working sets the element is fetched from LLC upon each read access due to cache trashing. This makes MSI issue an invalidate broadcast for each incrementation and the accumulated overhead is easily spotted in \reffig{fig:resultslab1}, it is also seen that the overhead become linearly to the size of the working set.

\begin{figure}[t]
	\center
	\includegraphics[width=0.7\textwidth]{lab1bars}
	\caption{Simulation results using various cache coherence protocols combined with different working sets and benchmarks.}
	\label{fig:resultslab1}
\end{figure}

\subsection{Task 3}
\label{sec:lab13}
\todo[inline]{
Compare MESI and MESI+migratory.
Why is one better than the other?
How does the behavior change when the dataset size changes?}
MESI-MG is a modified version of MESI where the S state is not utilized. If a cache reads a data element it will be forwarded from a remote private cache if it holds the data element in the E or M state, and then the remote cache invalidates it's copy.