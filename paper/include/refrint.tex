This technique is proposed by Agrawal et al. \cite{refrint} and is based on Access Recency. It is targeted towards caches and eDRAM, and thus can not be directly compared with the other solutions, but the main concept is of good use and the technique could be implemented DRAM as well. The concept is based on two types of unnecessary refreshes which originate from so called cold and hot rows. Cold rows are those used far apart in time or not used at all. The technique identifies and refreshes only those rows which are expected to be accessed in the near future, the rows that are used less frequent is invalidated. Hot rows consist of the rows that gets accessed frequently and thus can the technique postpone the preceding refresh to the accessed rows.

For the hot rows, an approach similar to Smart Refresh is employed. The differences are that Refrint does not maintain a counter for each row, but a snapshot of a global counter as well as the row's valid bit. When a row is accessed, the corresponding snapshot is updated with the current value of the global counter. Whenever the global counter steps to a new value, all normal accesses are stalled and the logic checks whether any of the valid row's snapshot  matches the global counter. If there is a match, a refresh is scheduled or the row is invalidated depending on the polices used for the cold rows. 

Four different policies can be applied for the cold rows, where the policies decide what to refresh; \textit{All}, \textit{Valid}, \textit{Dirty}, or \textit{WB(n,m)}. \textit{All} refreshes every row, regardless of whether it is valid or not. \textit{Valid} and \textit{Dirty} refreshes valid and dirty rows, respectively, and otherwise invalidate the row. \textit{WB(n,m)} refreshes a dirty row $n$ times before flushing it and changing the row state to valid clean, then the row is refreshed $m$ times after the last access before it is invalidated. $n$ and $m$ are time-out counters that are decremented upon refresh.

\todo[inline]{Drafty text below!}

Depending on the application's memory footprint and cache visibility the program is categorized to maximize the gain of the policies for cold rows. Visibility correspond to the amount of cache row accesses made by the application. If the application has high visibility, \textit{WB} is used and if the visibility is low, \textit{Valid} is used. A high visibility and a small footprint works best with small $n$ and $m$, whereas a large footprint is likely more usefull with small \textit{n} and \textit{m}. 

The technique modifies the MC. Which modifications and how large overhead? 5 bit snapshot for each row + state and n+m counters. some logic as well.

Presents the results. Add that we can not really use the result as they are from eDRAM.
