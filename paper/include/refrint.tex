This technique is proposed by Agrawal et al. \cite{refrint} and is based on Access Recency and Validity. It is targeted towards caches and eDRAM, and thus can not be directly compared with the other solutions, but the main concept is of good use and the technique could be implemented in DRAM as well. The concept is based on two types of unnecessary refreshes which originate from so called cold and hot rows. Cold rows are those used far apart in time or not used at all. The technique identifies and refreshes only those rows which are expected to be accessed in the near future, the rows that are used less frequent is invalidated. Hot rows consist of the rows that gets accessed frequently and thus can the technique postpone the preceding refresh to the accessed rows.

For the hot rows, an approach similar to Smart Refresh is employed. The differences are that Refrint does not maintain a counter for each row, but a snapshot of a global counter's highest bits as well as the row's valid bit. When a row is accessed, the corresponding snapshot is updated with the current value of the global counter. Whenever the global counter steps to a new value, all normal accesses are stalled and the logic checks whether any of the valid row's snapshot matches the global counter. If there is a match, a refresh is scheduled or the row is invalidated depending on the polices used for the cold rows. 

Four different policies can be applied for the cold rows, where the policies decide what to refresh; \textit{All}, \textit{Valid}, \textit{Dirty}, or \textit{WB(n,m)}. \textit{All} refreshes every row, regardless of whether it is valid or not. \textit{Valid} and \textit{Dirty} refreshes valid and dirty rows, respectively, and otherwise invalidate the row. \textit{WB(n,m)} refreshes a dirty row $n$ times before flushing it and changing the row state to valid clean, then the row is refreshed $m$ times after the last access before it is invalidated. Moreover, \textit{WB} is implemented using so called \textit{Count} bits, which is set either to $n$ or $m$ and is decremented upon refresh, as well as a \textit{State} bit.

Depending on the application's memory footprint and cache visibility the program is categorized to maximize the gain of the policies for cold rows, where visibility correspond to the number of cache row accesses made by the application. If the application has high visibility, \textit{WB} is used and if the visibility is low, \textit{Valid} is used. A high visibility and a small footprint works best with large $n$ and $m$, whereas a high visibility and a large footprint likely benefits more from small \textit{n} and \textit{m}. 

Refrint modifies the MC. The $N$ snapshot bits and a valid bit per DRAM row is stored in the MC and from experiments, Agrawal et al. found out that one or two are good values for $N$. To process the policies for the cold rows, decision logic as well as Count bits and State bit for each cache row is is needed. The decision logic is placed outside the MC, loosely coupled with it, whereas the Count and State bits are stored in eDRAM logically with the data. In simulations, Agrawal et al. set Count to five bits and $N$ to two bits, resulting in a total overhead of $0.015\%$ if row size is \textit{8~KB}.

Results indicated that Refrint lower the total power consumption by $70\%$ but increases execution time of a cache hierarchy when evaluated as eDRAM, compared to an ordinary cache hierarchy using SRAM. Even though Refrint speeds up the execution time compared to an eDRAM hierarchy without Refrint, the execution time is increased by $6\%$  with respect to the SRAM solution, due to the characteristics of eDRAM.